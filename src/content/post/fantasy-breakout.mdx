---
title: Predicting breakout sleepers in fantasy football
category: analytics
publishedAt: 2025-09-21
subTitle: Combining composite scoring with machine learning to spot tomorrow's NFL fantasy breakout performance
tags:
  - machine learning
---

## Undervalued players in fantasy football

Building predictive models for fantasy football presents unique challenges. The game involves countless variables ranging from player health, team dynamics, and weather conditions, to coaching decisions and defensive matchups. This complexity, combined with the inherent volatility of single-game performances, makes accurate prediction particularly difficult. My approach to fantasy football has reflected this observation: I typically enable auto draft, minimize trades and transactions. I usually adopt the role of watchmaker: creating my team and setting it in motion, intervening only when necessary.

Yet despite these challenges, patterns do emerge. Players with certain characteristics like favorable matchups, increasing snap counts, or specific team situations, tend to outperform expectations more often than pure chance would suggest. Participants who can identify these patterns and understand current NFL dynamics gain meaningful advantages.

More specifically, I am fascinated by finding undervalued players. I believe there are always players sitting on waivers who would be excellent replacements for injured or underperforming roster players. My hypothesis: every week, there are 3-5 available players who will outperform the lowest performer on your roster by at least 5 points. Of those possible 5 players, there is probably 1 who has a high potential for have a 10+ breakout performance that deserved a starting roster spot. The challenge is identifying them before they have a breakout performance. Let's test this hypothesis.

This blog post explores comparing two predictive approaches: using a composite Sleeper Score threshold versus a machine learning model that incorporates the Sleeper Score as one of many features. Using a dataset from the 2024 NFL season focusing on second-year player breakout predictions, I'll show how the ML model improved predictive accuracy over using the Sleeper Score threshold alone.

## The Sleeper Score: Quantifying Breakout Potential

Before diving into machine learning, we need a solid foundation built on fantasy football fundamentals. The Sleeper Score is a composite metric designed to identify players with the highest probability of breaking out. It combines six weighted factors that fantasy experts have long recognized as predictive of future success, now quantified into a systematic 175-point scale.

The Sleeper Score formula:

$$
S_{total} = w_1 \cdot S_{draft} + w_2 \cdot S_{performance} + w_3 \cdot S_{age} + w_4 \cdot S_{ecr} + w_5 \cdot S_{matchup} + w_6 \cdot S_{trend}
$$

### The Six Components of Sleeper Score

**1. Draft Capital (0-50 points) - The Opportunity Indicator**

Draft position reveals how NFL teams value a player's talent. The inverse weighting - where undrafted free agents score highest - reflects our focus on finding undervalued players. Players drafted early have already proven themselves; we're hunting for late-round picks and UDFAs who will exceed expectations.

- Undrafted Free Agent (UDFA): 50 points
- Draft pick > 200: 40 points
- Draft pick > 150: 30 points
- Draft pick > 100: 20 points
- Draft pick > 50: 10 points
- Draft pick ≤ 50: 0 points

**2. Performance History (0-30 points) - The Upside Gap**

Players with minimal Year 1 production have nowhere to go but up. This component rewards players who showed limited fantasy output in their rookie season, as they represent the largest potential improvement opportunity.

- Low production (&lt; 6 PPG for RB/WR, &lt; 4 PPG for TE): 30 points
- Minimal fantasy points: 20 points
- Moderate production (1-1.5x threshold): 20 points
- Higher production: 0 points

**3. Age Factor (0-20 points) - The Youth Advantage**

Younger players typically show steeper development curves. Players 22 and under are in prime physical development years and have more career runway for breakout performances.

- Age ≤ 22: 20 points
- Age ≤ 23: 15 points
- Age ≤ 24: 10 points
- Age > 24: 0 points

**4. Expert Consensus Ranking (0-20 points) - The Market Inefficiency**

FantasyPros ECR reveals where the fantasy community values players. Higher scores go to players with worse rankings (higher ECR numbers), indicating market undervaluation. This identifies the "wisdom of crowds" inefficiencies.

$$
\text{ECR Score} = 20 - \left(\frac{\text{ecr} - \text{min\_ecr}}{\text{max\_ecr} - \text{min\_ecr}}\right) \times 20
$$

**5. Defensive Matchup (0-30 points) - The Weekly Catalyst**

Matchups matter enormously in single-week performance. This position-specific component evaluates whether a player faces a weak defense in their relevant category (rush defense for RBs, pass defense for WRs/TEs).

- Opponent ranked 29-32 (worst defenses): 30 points
- Opponent ranked 25-28: 25 points
- Opponent ranked 21-24: 20 points
- Opponent ranked 17-20: 15 points
- Opponent ranked 13-16: 10 points
- Opponent ranked 9-12: 5 points
- Opponent ranked 1-8 (best defenses): 0 points

**6. Snap Count Trends (0-15 points) - The Momentum Signal**

Increasing playing time is the strongest leading indicator of fantasy production. This uses a 2-week sliding window to capture recent snap percentage momentum while filtering out single-week anomalies.

- Average delta ≥10%: 15 points (major increase)
- Average delta ≥5%: 12 points (significant increase)
- Average delta ≥2%: 8 points (moderate increase)
- Average delta >0%: 5 points (small increase)
- Average delta ≥-2%: 2 points (stable)
- Average delta &lt;-2%: 0 points (declining)

### Why This Rubric Identifies Breakout Candidates

The Sleeper Score succeeds because it captures the **convergence of opportunity and talent** that drives fantasy breakouts:

**Opportunity Identification:** The draft capital, snap trends, and matchup components identify when players are getting their chance. A UDFA with increasing snaps facing a bottom-tier defense represents maximum opportunity.

**Talent Validation:** While draft position matters, the age and ECR components ensure we're focusing on players the NFL and fantasy community still view as having upside. These aren't washed-up veterans—they're young players whose talent hasn't yet translated to fantasy production.

**Performance Gap:** The inverse relationship with Year 1 production is crucial. Players who barely played or produced poorly have massive room for improvement. A player averaging 2 PPG can realistically jump to 12+ PPG with increased opportunity. A player already at 10 PPG would need to reach elite status (20+ PPG) for similar improvement—far less likely for a waiver wire candidate.

**Weekly Volatility Capture:** Unlike seasonal projections, this rubric evaluates week-by-week factors (matchups, snap trends) that drive single-game explosions. Fantasy managers need players who can win a specific week, not necessarily maintain season-long consistency.

**Market Inefficiency Exploitation:** By focusing on players ranked outside the top 100 in ECR, we're targeting the space where fantasy managers aren't paying attention. These players sit on waivers, available for free, despite having quantifiable breakout indicators.

The 175-point maximum scale provides granular differentiation between candidates. As we'll see in the analysis below, we'll compare two approaches: using the Sleeper Score alone (selecting the top 10 highest-scoring players each week) versus a machine learning model that uses the Sleeper Score as one of many input features to generate breakout probabilities.

## Analyzing 2024 for breakout performances

We analyzed 263 second-year player performances across 16 weeks of the 2024 NFL season (weeks 3-18), focusing on running backs, wide receivers, and tight ends. Each week, we predicted the top 10 most likely breakout candidates (players exceeding 5+ point fantasy improvement).

We consider these second-year players "sleepers" because they have an [Expert Consensus Rating](https://www.fantasypros.com/about/faq/football-draft-accuracy-methodology/) (which is basically average fantasy draft position) of greater than 100. So in a league of 12 teams, most rosters would be full before these players are drafted.

To build our predictive system, we start by building a composite Sleeper Score using six weighted factors: draft capital, performance history, age, expert consensus rankings, defensive matchups, and snap count trends. Our baseline approach simply selects the top 10 players with the highest Sleeper Scores each week. Across 160 top-10 predictions (10 per week × 16 weeks), this baseline approach correctly identified 39 breakout performances, achieving 24.4% accuracy.

We then built a machine learning model that uses the
Sleeper Score as one of its input features, combining
it with the six individual component scores, binary
playing time indicators, performance momentum
metrics, and 40+ other features. Rather than simply
ranking by Sleeper Score, the ML model learns how to
weight the Sleeper Score alongside all these features
to generate breakout probabilities. The ML model
achieved 52 correct predictions from 160
opportunities - a 32.5% accuracy rate and 33%
relative improvement over using Sleeper Score alone

The ML model demonstrates meaningful improvements in prediction accuracy and consistency across the 2024 NFL season, making it more reliable for fantasy football decision-making.

The data tells a clear story of improvement:

| Metric | Sleeper Score Alone | ML Model (with Sleeper Score) | Improvement |
|--------|-------------------|-----------------|-------------|
| **Weekly Accuracy** | 24.4% | 31.9% | +7.5 pts |
| **Total Correct Predictions** | 39 hits | 51 hits | +31% |
| **False Positive Rate** | Lower precision | Higher precision | Varies by week |
| **Best Week Performance** | 6 hits (Week 4) | 8 hits (Week 3, 4) | +33% |
| **Consistency** | More volatile | More stable | Better reliability |

**Weekly Performance Highlights:**
- **Week 3**: 2 hits (Sleeper Score) vs 8 hits (ML) - Best ML performance
- **Week 4**: 6 hits (Sleeper Score) vs 8 hits (ML) - Both approaches performed well
- **Week 16**: 2 hits (Sleeper Score) vs 6 hits (ML) - Late season improvement
- **Week 17**: 2 hits (Sleeper Score) vs 6 hits (ML) - Strong finish

The consistency improvement is particularly significant - the ML model maintained more stable performance across weeks, with fewer volatile swings between high and low-performing weeks.

## Predictive results from analyzing 16 weeks in 2024

<WeeklyPerformanceChart />

<WeeklyDataTable />

<Sticky header="Open source written in R, F#, and trained using ML.NET">
    This analysis leverages comprehensive NFL and fantasy football data sources processed through ML.NET:

    **Data Sources:**
    - **NFL Data**: `nflfastR` for player rosters and schedules; `nflreadr` for player stats, snap counts, roster data, and injury reports
    - **Fantasy Data**: FantasyPros expert consensus rankings (ECR) for players ranked 100-300, excluding QBs

    **Key Metrics Collected:**
    - Second-year player rosters from the current season
    - Snap counts with week-to-week changes (Year 1 and Year 2 data)
    - Fantasy points with performance deltas (previous week vs current)
    - Defense rankings from optional local CSV files
    - Active roster status and injury report data
    - Current week opponents for matchup analysis

    **ML Pipeline**: The combined data feeds into an ML.NET SDCA Logistic Regression model that identifies second-year fantasy breakout candidates with comprehensive metrics for predictive analysis.
    <br />
    [You can follow these directions to recreate all the data in this blog post.](https://github.com/joe307bad/fastbreak/blob/main/server/src/Fastbreak.Research.Cli/Commands/02-nfl-fantasy-sleeper-breakout/README.md)
</Sticky>

## Combining Two Approaches: Sleeper Score Threshold + ML Model

The baseline approach uses the Sleeper Score as a simple ranking threshold. The Sleeper Score employs a weighted combination of six factors (listed above). Rather than using Sleeper Score alone, the ML model treats it as one input feature among many.

The ML model employs ML.NET's **SDCA Logistic
Regression (Stochastic Dual Coordinate Ascent)**
classifier, a sophisticated binary classification
algorithm optimized for large-scale learning. This
algorithm was chosen for its ability to handle
high-dimensional feature spaces efficiently while
providing probabilistic outputs perfect for
confidence scoring.

ML.NET Algorithm Configuration:
  - Algorithm: SDCA Logistic Regression (with default
regularization parameters)
  - Feature Normalization: MinMax scaling to [0,1]
range

**Key Insight**: The ML model uses the Sleeper Score as
one of its 40+ input features, along with the six
individual component scores (draft capital,
performance history, age, ECR, matchup, snap trends),
previous week performance, snap percentage changes,
sliding window averages, and momentum indicators.
Rather than using fixed weights like the baseline
approach, the ML model learns how to weight the
Sleeper Score relative to all other features. The
training pipeline:

```
Pipeline = Concatenate Features → Normalize MinMax → SDCA Logistic Regression
```

### The Prediction Process: From Rankings to Hits

Our evaluation methodology follows a rigorous process to ensure fair comparison between the composite scoring baseline and ML-enhanced predictions:

**Step 1: Generate Predictions**
- For each week, calculate Sleeper Scores for all eligible players
- Run the ML model to generate confidence probabilities (0-100%) using Sleeper Score + 40+ other features

**Step 2: Sort and Select Top Candidates**
- **Baseline approach**: Sort all players by Sleeper score (descending) → Select top 10
- **ML approach**: Sort all players by ML confidence (descending) → Select top 10

**Step 3: Mark Hits**
- For Sleeper Top 10: Mark as "hit" if player achieved 5+ fantasy point improvement
- For ML Top 10: Mark as "hit" if player achieved 5+ fantasy point improvement

**Step 4: How ML Generates Confidence Scores**
The ML confidence score represents the probability of a breakout. The SDCA Logistic Regression model learns optimal weights for all input features, including:

- **Sleeper Score** (composite of 6 factors)
- **Individual component scores** (draft capital, performance, age, ECR, matchup, snap trends)
- **Binary playing time indicators**
- **Performance momentum metrics**
- **40+ additional features** capturing player and team context

The model outputs a probability via the logistic function applied to the weighted sum of all features. Critically, the ML model learns that the Sleeper Score should be weighted differently based on context - for example, it might learn that high Sleeper Scores are more predictive for running backs than wide receivers, or that snap count trends become more important than draft capital late in the season.

This comparison ensures we're evaluating the best predictions from each method. The ML model doesn't just re-rank Sleeper scores - it learns how to combine the Sleeper Score with dozens of other signals to generate more accurate breakout probabilities.

## Week-by-Week Performance: ML vs Sleeper Score Threshold

When we compare how the ML model performed against using Sleeper Score as a simple ranking threshold, clear patterns emerge across the season.

**Early Season (Weeks 3-6)**: The ML model showed solid
early-season performance with 22 top-10 hits compared
to 17 from the baseline Sleeper Score approach,
demonstrating a 29% improvement in identifying
breakout candidates.

**Mid-Season Performance (Weeks 7-12)**: This is where
the machine learning model truly excelled. The ML
model achieved 28 top-10 hits versus just 14 from
Sleeper Score ranking—exactly double the baseline
performance. This period showcased the ML model's
ability to learn and adapt to mid-season dynamics
that simple ranking couldn't capture.

**Late Season (Weeks 13-18)**: The final stretch showed
more competitive results with 23 ML hits compared to
19 from the Sleeper Score approach, representing a
21% improvement. Both models faced increased
unpredictability in late-season conditions, but the
ML model maintained its edge.

## Why ML Outperforms Using Sleeper Score Alone

### The Foundation: Sleeper Score as a Fixed-Weight System

Using the Sleeper Score as a simple ranking threshold has clear advantages:

**Domain Knowledge Integration**: The Sleeper Score encapsulates years of fantasy football wisdom - draft capital matters, age curves exist, opportunity drives production. It codifies expert knowledge into a systematic framework.

**Interpretability**: Sleeper Score rankings are fully explainable. You can trace exactly why a player scored highly and understand the reasoning behind each prediction.

**Robust Feature Engineering**: The Sleeper Score provides a sophisticated signal that captures the most important predictive factors in a single metric.

However, the fixed-weight nature of this approach limits its adaptability. All six components maintain constant weights regardless of context.

### The ML Advantage: Learning Optimal Feature Weights

The machine learning model achieves superior results by incorporating the Sleeper Score but adding critical capabilities:

**Learned Weights vs Fixed Weights**: Rather than using pre-defined weights (50 for draft capital, 30 for performance, etc.), the ML model learns optimal weights for the Sleeper Score relative to 40+ other features. It discovers that the Sleeper Score's predictive power varies by context.

**Context-Aware Weighting**: The model learns when the Sleeper Score should be trusted more or less based on player position, team context, and game situation. A high Sleeper Score for a RB might be more predictive than the same score for a WR.

**Non-Linear Relationships**: While the Sleeper Score uses linear weights, ML can discover non-linear patterns. For example, a Sleeper Score of 120 might not be twice as predictive as a score of 60.

**Temporal Learning**: The model identifies seasonal patterns, learning that certain components of the Sleeper Score become more or less important as the year progresses. Early season predictions might weight draft capital heavily, while late season predictions emphasize snap trends.

**Feature Interactions**: ML discovers complex relationships between the Sleeper Score and other variables. For instance, it might learn that high Sleeper Scores combined with increasing snap counts are more predictive than high scores with stable snaps.

The key insight: The ML model doesn't ignore the Sleeper Score - it uses it as one valuable input while learning how to optimally weight it alongside dozens of other features.

## Empirical Performance Analysis

Our evaluation across 16 weeks of NFL data provides quantitative evidence for each methodology's effectiveness:

### ML.NET Model Feature Importance

The SDCA Logistic Regression model identifies which features most strongly predict breakout performances. The top 15 features used in our model, ranked by predictive importance:

1. **SleeperScore** - The composite domain expertise score (highest weight)
2. **PrevWeekFp** - Previous week's fantasy points
3. **SnapPctChange** - Week-over-week snap percentage change
4. **SlidingWindowAvgDelta** - 2-week moving average of performance changes
5. **SnapIncreaseMomentum** - Trend in snap count increases
6. **HasPositiveTrend** - Binary indicator of upward trajectory
7. **SignificantSnapJump** - Detection of 20%+ snap share increase
8. **PerformanceScore** - Historical production metrics
9. **AgeScore** - Age-based potential weighting
10. **EcrScore** - Expert consensus ranking integration
11. **MatchupScore** - Defensive matchup quality
12. **YearsExp** - Years of NFL experience
13. **AvgSnapPctY1** - First-year snap percentage average
14. **FpPerSnapY1** - First-year fantasy efficiency
15. **AvgSnapPctY2** - Second-year snap percentage average

### Model Evaluation Metrics

**ML.NET Binary Classification Metrics:**
  - **Binary Accuracy**: 70.8% - Correct classification
rate
  - **F1 Score**: 0.399 - Balanced precision/recall
performance
  - **Positive Precision**: 34.1% - When predicting
breakout, correct 34.1% of time
  - **Positive Recall**: 54.8% - Catches 54.8% of actual
breakouts

**Comparative Performance Metrics:**
  - **ML Model Top-10 Accuracy**: 31.9% (51 hits / 160
opportunities)
  - **Sleeper Score Threshold Top-10 Accuracy**: 24.4% (39
hits / 160 opportunities)
  - **Performance Improvement**: +7.5 percentage points
(+31% relative improvement)
  - **Overall ML Prediction Accuracy**: 34.9% (across all
predictions, not just top 10)

The comparative metrics demonstrate meaningful improvement: the ML model correctly identified 31% more breakout performances than using Sleeper Score rankings alone. From a practical standpoint, this means finding significantly more of those league-winning waiver wire pickups that deliver big weeks.

**Why This Matters**: The ML model has access to the same Sleeper Score that the baseline approach uses, but learns how to combine it with additional signals for better predictions. This isn't "ML vs domain expertise" - it's "fixed-weight domain expertise" vs "domain expertise enhanced by learned feature weights."

## Case Study Analysis: 2024 Performance Examples

Examining specific player predictions provides insight into where the ML model excelled and where both methods struggled:

**Biggest ML Successes (Model Actually Predicted These):**

**Tyjae Spears (RB, Tennessee)** - Week 15: ML confidence of 51.5% correctly identified a massive 23.9-point explosion despite a low composite score of 59. This demonstrates the ML model's ability to find value where traditional metrics fall short.

**Jordan Addison (WR, Minnesota)** - Week 4: ML confidence of 70.3% correctly identified a 22.9-point breakout with low composite scoring (46). This high-confidence prediction showcases when the model is most certain.

**Quentin Johnston (WR, LAC)** - Week 9: ML confidence of 57.2% identified a 22.0-point breakout despite very low composite scoring (57). Shows the model can find value in unexpected places.

**Strong ML-Only Successes:**

**Jaxon Smith-Njigba (WR, Seattle)** - Week 11: ML confidence of 79.0% correctly predicted a 21.8-point performance while composite scoring was too low (57) to make the top 10. This was one of the highest confidence ML predictions that paid off.

**Tank Bigsby (RB, JAX)** - Week 7: ML confidence of 58.6% identified a 21.4-point breakout with composite score of 89. Shows convergence between both methods.

**Josh Downs (WR, IND)** - Week 8: ML confidence of 68.2% identified a 20.9-point performance that composite scoring missed (score: 36). Another example of the ML model detecting actionable signals that traditional analysis overlooks.

The pattern? The ML model excels at finding players with moderate-to-strong breakout potential that Sleeper Score rankings alone miss. Critically, these successes often involve cases where the Sleeper Score was moderately high but not top-10, and the ML model learned to weight other features (like snap momentum or recent performance) to elevate these players into its top-10 predictions. The biggest fantasy explosions often remain unpredictable regardless of methodology.

## Understanding the Performance Differential: Data Complexity and Pattern Recognition

The superior performance of the machine learning approach stems from its capacity to process high-dimensional data and identify complex patterns. Several factors contribute to this advantage:

**High-Dimensional Feature Space**: With the Sleeper Score plus 40+ additional features per player observation (including snap count distributions, efficiency metrics, team context variables, and temporal trends), the ML model can learn which combinations matter most. The fixed-weight Sleeper Score approach cannot adjust to these patterns.

**Non-Linear Interaction Effects**: Consider how the Sleeper Score interacts with other signals. The ML model discovers that:
- A high Sleeper Score combined with increasing snaps is more predictive than a high score with stable snaps
- Draft capital (one component of Sleeper Score) matters more for RBs than WRs
- Recent performance momentum can override a mediocre Sleeper Score
- Matchup quality (another Sleeper Score component) becomes more predictive in certain game scripts

The baseline approach treats the Sleeper Score as a standalone metric, while ML learns these contextual nuances.

**Temporal Pattern Recognition**: The ML model identifies seasonal trends that fixed weights cannot capture. For example, it learns that early in the season, the Sleeper Score's draft capital component is highly predictive, but late in the season, snap trend components become more important. The baseline approach uses constant weights year-round.

These capabilities explain why the ML model outperforms using Sleeper Score alone - it incorporates the domain knowledge encoded in the Sleeper Score but learns how to weight it optimally based on context.

## Methodology Selection Framework

The choice between using Sleeper Score rankings and ML-enhanced predictions should be guided by specific needs:

**When to Use Sleeper Score Rankings Alone:**
- You need fully transparent, explainable predictions
- You want to understand exactly why each player ranks highly
- You're working with limited computational resources
- You're making decisions that require stakeholder buy-in
- You need rapid week-to-week adjustments to scoring weights

**When to Use the ML Model:**
- Predictive accuracy is the primary objective
- You have access to the model's predictions (via API or weekly outputs)
- You're comfortable with probabilistic outputs
- You want the model to learn optimal feature weights from historical data
- You value performance over interpretability

**Best of Both Worlds:**
- Use Sleeper Score rankings to understand player opportunity profiles
- Use ML predictions for actual roster decisions
- Let ML feature importance analysis reveal which Sleeper Score components matter most
- Use ML-discovered patterns to refine future Sleeper Score weighting

## Future Directions in Fantasy Analytics

Our analysis illuminates several promising research directions:

**Feature Engineering Optimization**: The quality and relevance of input features may matter more than algorithmic sophistication, suggesting focus areas for data collection and preprocessing.

**Ensemble Methodologies**: Combining predictions from multiple models (such as averaging composite scores and ML confidence) often outperforms individual approaches, offering a path to leverage both interpretability and accuracy.

**Adaptive Model Architecture**: Systems that can adjust parameter weights during seasons show potential for handling evolving league dynamics.

**Position-Specific Modeling**: Different player positions may benefit from specialized prediction frameworks optimized for their unique performance patterns.

## Conclusion

This analysis demonstrates that machine learning models can achieve meaningful improvements over using composite Sleeper Scores as fixed-weight ranking thresholds. By comparing Sleeper Score rankings against an ML model that incorporates the Sleeper Score as one of 40+ features, we found the ML approach improved predictive accuracy by 7.5 percentage points (31% relative improvement).

The key insight is that this isn't "ML vs domain expertise" - both approaches use domain expertise. The Sleeper Score encodes fantasy football wisdom into six weighted components, and the ML model uses that same Sleeper Score as an input feature. The difference is that ML learns optimal weights while the baseline approach uses fixed weights.

The improvement translates to identifying 31% more actual breakout performances, meaning more league-winning waiver wire pickups across a 16-week season. The ML model doesn't replace the Sleeper Score - it enhances it by learning which contexts make high Sleeper Scores more or less predictive.

For fantasy football analytics, this comparison offers a practical path forward:

- **Sleeper Score rankings alone**: Fully transparent and explainable, perfect for understanding player opportunity profiles
- **ML model with Sleeper Score as a feature**: Superior accuracy by learning context-dependent feature weights

The future of fantasy analytics likely involves both: using Sleeper Scores to understand *why* a player might break out, and using ML predictions to determine *which* high-Sleeper-Score players are most likely to actually deliver. Domain expertise and machine learning aren't competing approaches - they're complementary tools that work best together.